{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Time-Series Forecasting of Engagement Levels - Data Preprocessing\n",
        "\n",
        "## Problem Statement\n",
        "Predict future engagement levels from past gaze, EEG, and GSR signals using sequence-to-sequence models.\n",
        "\n",
        "## Data Overview\n",
        "- **Target**: Engagement levels (continuous score from ENG.csv)\n",
        "- **Inputs**: \n",
        "  - EEG.csv: Brainwave bands (Delta, Theta, Alpha, Beta, Gamma)\n",
        "  - EYE.csv + IVT.csv: Eye-tracking signals (fixation, saccade, pupil)\n",
        "  - GSR.csv: Skin conductance/resistance values\n",
        "\n",
        "## Preprocessing Pipeline\n",
        "1. Data synchronization and timestamp alignment\n",
        "2. Feature extraction from multimodal signals\n",
        "3. Sliding window approach for sequence-to-value prediction\n",
        "4. Normalization and label preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Initial Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load all data files\n",
        "print(\"Loading data files...\")\n",
        "\n",
        "# Load engagement data (target variable)\n",
        "eng_data = pd.read_csv('../Data/ENG.csv')\n",
        "print(f\"Engagement data shape: {eng_data.shape}\")\n",
        "\n",
        "# Load EEG data\n",
        "eeg_data = pd.read_csv('../Data/EEG.csv')\n",
        "print(f\"EEG data shape: {eeg_data.shape}\")\n",
        "\n",
        "# Load GSR data\n",
        "gsr_data = pd.read_csv('../Data/GSR.csv')\n",
        "print(f\"GSR data shape: {gsr_data.shape}\")\n",
        "\n",
        "# Load eye-tracking data\n",
        "eye_data = pd.read_csv('../Data/EYE.csv')\n",
        "print(f\"Eye-tracking data shape: {eye_data.shape}\")\n",
        "\n",
        "# Load IVT data\n",
        "ivt_data = pd.read_csv('../Data/IVT.csv')\n",
        "print(f\"IVT data shape: {ivt_data.shape}\")\n",
        "\n",
        "print(\"\\nData loading completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explore data structure and basic statistics\n",
        "print(\"=== ENGAGEMENT DATA ===\")\n",
        "print(eng_data.head())\n",
        "print(f\"\\nEngagement data info:\")\n",
        "print(eng_data.info())\n",
        "print(f\"\\nEngagement statistics:\")\n",
        "print(eng_data.describe())\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"=== EEG DATA ===\")\n",
        "print(f\"EEG columns: {list(eeg_data.columns)}\")\n",
        "print(f\"\\nEEG data info:\")\n",
        "print(eeg_data.info())\n",
        "print(f\"\\nEEG statistics (first 10 columns):\")\n",
        "print(eeg_data.iloc[:, :10].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explore GSR and Eye-tracking data\n",
        "print(\"=== GSR DATA ===\")\n",
        "print(f\"GSR columns: {list(gsr_data.columns)}\")\n",
        "print(f\"\\nGSR data info:\")\n",
        "print(gsr_data.info())\n",
        "print(f\"\\nGSR statistics:\")\n",
        "print(gsr_data.describe())\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"=== EYE-TRACKING DATA ===\")\n",
        "print(f\"Eye-tracking columns: {list(eye_data.columns)}\")\n",
        "print(f\"\\nEye-tracking data info:\")\n",
        "print(eye_data.info())\n",
        "print(f\"\\nEye-tracking statistics (first 10 columns):\")\n",
        "print(eye_data.iloc[:, :10].describe())\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"=== IVT DATA ===\")\n",
        "print(f\"IVT columns: {list(ivt_data.columns)}\")\n",
        "print(f\"\\nIVT data info:\")\n",
        "print(ivt_data.info())\n",
        "print(f\"\\nIVT statistics (first 10 columns):\")\n",
        "print(ivt_data.iloc[:, :10].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Synchronization and Timestamp Alignment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert timestamps to datetime and unix time for synchronization\n",
        "def prepare_timestamps(df, timestamp_col, unix_col=None):\n",
        "    \"\"\"Prepare timestamps for synchronization\"\"\"\n",
        "    df = df.copy()\n",
        "    \n",
        "    # Convert timestamp to datetime\n",
        "    if timestamp_col in df.columns:\n",
        "        df[timestamp_col] = pd.to_datetime(df[timestamp_col])\n",
        "    \n",
        "    # Use unix time if available, otherwise convert from datetime\n",
        "    if unix_col and unix_col in df.columns:\n",
        "        df['unix_time'] = df[unix_col]\n",
        "    else:\n",
        "        df['unix_time'] = df[timestamp_col].astype('int64') // 10**9\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Prepare timestamps for each dataset\n",
        "print(\"Preparing timestamps for synchronization...\")\n",
        "\n",
        "# Engagement data\n",
        "eng_data = prepare_timestamps(eng_data, 'Timestamp')\n",
        "print(f\"Engagement time range: {eng_data['Timestamp'].min()} to {eng_data['Timestamp'].max()}\")\n",
        "\n",
        "# EEG data\n",
        "eeg_data = prepare_timestamps(eeg_data, 'TimeStamp', 'UnixTime')\n",
        "print(f\"EEG time range: {eeg_data['TimeStamp'].min()} to {eeg_data['TimeStamp'].max()}\")\n",
        "\n",
        "# GSR data\n",
        "gsr_data = prepare_timestamps(gsr_data, 'Timestamp', 'UnixTime')\n",
        "print(f\"GSR time range: {gsr_data['Timestamp'].min()} to {gsr_data['Timestamp'].max()}\")\n",
        "\n",
        "# Eye-tracking data\n",
        "eye_data = prepare_timestamps(eye_data, 'Timestamp', 'UnixTime')\n",
        "print(f\"Eye-tracking time range: {eye_data['Timestamp'].min()} to {eye_data['Timestamp'].max()}\")\n",
        "\n",
        "# IVT data\n",
        "ivt_data = prepare_timestamps(ivt_data, 'Timestamp', 'UnixTime')\n",
        "print(f\"IVT time range: {ivt_data['Timestamp'].min()} to {ivt_data['Timestamp'].max()}\")\n",
        "\n",
        "print(\"\\nTimestamp preparation completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find common time range for all datasets\n",
        "def find_common_time_range(datasets):\n",
        "    \"\"\"Find the common time range across all datasets\"\"\"\n",
        "    start_times = [df['unix_time'].min() for df in datasets if not df.empty]\n",
        "    end_times = [df['unix_time'].max() for df in datasets if not df.empty]\n",
        "    \n",
        "    common_start = max(start_times)\n",
        "    common_end = min(end_times)\n",
        "    \n",
        "    return common_start, common_end\n",
        "\n",
        "# Find common time range\n",
        "common_start, common_end = find_common_time_range([eng_data, eeg_data, gsr_data, eye_data, ivt_data])\n",
        "\n",
        "print(f\"Common time range:\")\n",
        "print(f\"Start: {datetime.fromtimestamp(common_start)}\")\n",
        "print(f\"End: {datetime.fromtimestamp(common_end)}\")\n",
        "print(f\"Duration: {(common_end - common_start) / 3600:.2f} hours\")\n",
        "\n",
        "# Filter all datasets to common time range\n",
        "eng_data = eng_data[(eng_data['unix_time'] >= common_start) & (eng_data['unix_time'] <= common_end)].copy()\n",
        "eeg_data = eeg_data[(eeg_data['unix_time'] >= common_start) & (eeg_data['unix_time'] <= common_end)].copy()\n",
        "gsr_data = gsr_data[(gsr_data['unix_time'] >= common_start) & (gsr_data['unix_time'] <= common_end)].copy()\n",
        "eye_data = eye_data[(eye_data['unix_time'] >= common_start) & (eye_data['unix_time'] <= common_end)].copy()\n",
        "ivt_data = ivt_data[(ivt_data['unix_time'] >= common_start) & (ivt_data['unix_time'] <= common_end)].copy()\n",
        "\n",
        "print(f\"\\nFiltered dataset sizes:\")\n",
        "print(f\"Engagement: {eng_data.shape[0]} samples\")\n",
        "print(f\"EEG: {eeg_data.shape[0]} samples\")\n",
        "print(f\"GSR: {gsr_data.shape[0]} samples\")\n",
        "print(f\"Eye-tracking: {eye_data.shape[0]} samples\")\n",
        "print(f\"IVT: {ivt_data.shape[0]} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Resampling to Consistent Frequency\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resample all datasets to a consistent frequency (1 Hz = 1 sample per second)\n",
        "def resample_to_frequency(df, unix_col, target_freq=1.0):\n",
        "    \"\"\"Resample data to target frequency using interpolation\"\"\"\n",
        "    df = df.copy()\n",
        "    \n",
        "    # Create a regular time index\n",
        "    start_time = df[unix_col].min()\n",
        "    end_time = df[unix_col].max()\n",
        "    time_index = np.arange(start_time, end_time + 1/target_freq, 1/target_freq)\n",
        "    \n",
        "    # Create new dataframe with regular time index\n",
        "    resampled_df = pd.DataFrame({'unix_time': time_index})\n",
        "    \n",
        "    # Merge with original data and interpolate\n",
        "    df_merged = pd.merge(resampled_df, df, on='unix_time', how='left')\n",
        "    \n",
        "    # Interpolate missing values for numeric columns\n",
        "    numeric_cols = df_merged.select_dtypes(include=[np.number]).columns\n",
        "    for col in numeric_cols:\n",
        "        if col != 'unix_time':\n",
        "            df_merged[col] = df_merged[col].interpolate(method='linear')\n",
        "    \n",
        "    return df_merged\n",
        "\n",
        "print(\"Resampling datasets to 1 Hz frequency...\")\n",
        "\n",
        "# Resample each dataset\n",
        "eng_resampled = resample_to_frequency(eng_data, 'unix_time', 1.0)\n",
        "eeg_resampled = resample_to_frequency(eeg_data, 'unix_time', 1.0)\n",
        "gsr_resampled = resample_to_frequency(gsr_data, 'unix_time', 1.0)\n",
        "eye_resampled = resample_to_frequency(eye_data, 'unix_time', 1.0)\n",
        "ivt_resampled = resample_to_frequency(ivt_data, 'unix_time', 1.0)\n",
        "\n",
        "print(f\"Resampled dataset sizes:\")\n",
        "print(f\"Engagement: {eng_resampled.shape[0]} samples\")\n",
        "print(f\"EEG: {eeg_resampled.shape[0]} samples\")\n",
        "print(f\"GSR: {gsr_resampled.shape[0]} samples\")\n",
        "print(f\"Eye-tracking: {eye_resampled.shape[0]} samples\")\n",
        "print(f\"IVT: {ivt_resampled.shape[0]} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
